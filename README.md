# Ponderadas
Contains proposed solutions for the evaluated exercises

# 1. Ponderada 1

Passos para a cria√ß√£o da imagem:

Criando um ambiente virtual:

```bash
python3 -m venv venv
source /venv/bin/activate
mkdir src && cd src
```

Instalando as depend√™ncias:

```bash
pip install fastapi
pip install "uvicorn[standard]"
pip freeze > requirements.txt
```

Ap√≥s a cria√ß√£o do Dockerfile, executar os seguintes comandos no terminal:

```bash
docker build -t python-img .
docker run -p 3000:80 --name fastapi-server python-img

```

O container j√° est√° rodando nossa aplica√ß√£o em FASTAPI ü•≥!

Publicando a imagem no Dockerhub:

```bash
docker login
docker tag python-img hallzero/inteli:0.0.x
docker push hallzero/inteli:0.0.x
```

# 2. Ponderada 2

Este projeto prop√µe uma solu√ß√£o para o exerc√≠cio ponderado 2 utilizando express como API, sequelize como ORM, postgres para o Banco de Dados, e HTML puro (At√© o momento) para o frontend.

# Arquivo docker-compose.yaml - Explica√ß√£o

Este arquivo `docker-compose.yaml` cont√©m a defini√ß√£o de um ambiente Docker composto por dois servi√ßos: um banco de dados PostgreSQL e uma API Express.

## Servi√ßo `db` - Banco de Dados PostgreSQL

Este servi√ßo utiliza a imagem oficial do PostgreSQL vers√£o 15.4. Ele fornece um banco de dados persistente para a aplica√ß√£o.

## Servi√ßo `api` - API Express

Este servi√ßo utiliza uma imagem chamada `hallzero/express-p2:latest`, contendo uma aplica√ß√£o Express para a API.

## Como Usar

1. Certifique-se de ter o Docker e o Docker Compose instalados em seu sistema.
2. Clone este reposit√≥rio para sua m√°quina, se ainda n√£o o tiver feito.
3. Navegue at√© o diret√≥rio onde o arquivo `docker-compose.yaml` est√° localizado.
4. Execute o comando `docker-compose up -d` para iniciar os servi√ßos em segundo plano.
5. Os servi√ßos ser√£o iniciados e a API estar√° dispon√≠vel em `http://localhost:3000`.

# Arquivo database.js - Explica√ß√£o

Este arquivo cont√©m a configura√ß√£o e a defini√ß√£o dos modelos de dados utilizando o m√≥dulo Sequelize para interagir com um banco de dados PostgreSQL.

## Conex√£o com o Banco de Dados

O c√≥digo inicia importando os m√≥dulos `Sequelize` e `DataTypes` do pacote 'sequelize'. Em seguida, uma inst√¢ncia do Sequelize √© criada para se conectar ao banco de dados PostgreSQL. As configura√ß√µes de conex√£o incluem o nome do banco de dados, o nome de usu√°rio, a senha, o host e a porta.

A fun√ß√£o `sequelize.authenticate()` √© usada para verificar se a conex√£o com o banco de dados √© bem-sucedida. Se a autentica√ß√£o for bem-sucedida, uma mensagem "Connected to the database" ser√° exibida. Caso contr√°rio, um erro ser√° logado.

## Modelos de Dados

### Modelo 'User'

O primeiro modelo definido √© 'User', que representa informa√ß√µes de um usu√°rio. Ele possui as seguintes colunas:

- `id`: Um n√∫mero inteiro com incremento autom√°tico e chave prim√°ria.
- `name`: Uma string que n√£o pode ser nula (ou seja, √© obrigat√≥ria).
- `password`: Uma string para armazenar a senha do usu√°rio.

### Modelo 'Task'

O segundo modelo definido √© 'Task', que representa uma tarefa. Ele possui as seguintes colunas:

- `id`: Um n√∫mero inteiro com incremento autom√°tico e chave prim√°ria.
- `description`: Uma string para armazenar a descri√ß√£o da tarefa.
- `done`: Um valor booleano para indicar se a tarefa est√° conclu√≠da.
- `user_id`: Uma refer√™ncia a um usu√°rio por meio da coluna `id` do modelo 'User'.

## Inicializa√ß√£o e Sincroniza√ß√£o

A fun√ß√£o `init()` √© ass√≠ncrona e executa a sincroniza√ß√£o dos modelos com o banco de dados usando `sequelize.sync({ force: true })`. Isso cria as tabelas correspondentes aos modelos. Um usu√°rio de exemplo √© criado com o nome 'teste' e senha 'teste123' usando `User.create()`.

# Arquivo login.js - Explica√ß√£o

Este arquivo cont√©m um m√≥dulo respons√°vel por lidar com o processo de autentica√ß√£o de um usu√°rio e a gera√ß√£o de um token de acesso usando a biblioteca `jsonwebtoken`. O objetivo √© validar as credenciais do usu√°rio e fornecer um token para acesso autenticado.

## Vari√°veis de Ambiente

As vari√°veis de ambiente `JWT_SECRET` e `JWT_ALGORITHM` s√£o carregadas a partir do arquivo `.env` usando `process.env`. Elas representam a chave secreta usada para assinar o token e o algoritmo de criptografia usado na gera√ß√£o do token, respectivamente.

O fluxo do c√≥digo √© o seguinte:

1. O c√≥digo chama a fun√ß√£o `readUserByName()` para buscar informa√ß√µes do usu√°rio com base no nome fornecido na solicita√ß√£o.

2. Se nenhum usu√°rio for encontrado ou se a senha fornecida na solicita√ß√£o n√£o coincidir com a senha armazenada no banco de dados, uma resposta de erro com status 403 (Acesso Proibido) √© enviada de volta ao cliente, indicando que o login √© inv√°lido.

3. Se o usu√°rio for encontrado e as credenciais estiverem corretas, a senha do objeto `user` √© exclu√≠da para evitar o envio dela de volta como resposta.

4. Um token de acesso √© gerado usando `jwt.sign()`, que recebe o nome do usu√°rio, a chave secreta e o algoritmo como argumentos. O token gerado √© inclu√≠do em uma resposta JSON enviada de volta ao cliente.

## Uso

Este m√≥dulo √© projetado para ser chamado em uma rota que lida com a autentica√ß√£o do usu√°rio. O nome de usu√°rio e senha s√£o fornecidos na solicita√ß√£o e o m√≥dulo executa a autentica√ß√£o, retornando um token de acesso em caso de sucesso.

# 3. Ponderada 3

Este projeto tem como objetivo a produ√ß√£o de um modelo preditivo e uma API que, a partir dos dados passados, consiga prever um valor.

## Estrutura de Pastas:

Todo o processo de Limpeza de dados e treinamento est√° contido em 'machine-learning.ipynb', de onde √© gerado o modelo propriamente dito em um arquivo .pkl 'finalized_model.pkl'.

```
‚îî‚îÄ‚îÄ ponderada3/
    ‚îî‚îÄ‚îÄ src/
        ‚îú‚îÄ‚îÄ dataset/
        ‚îÇ   ‚îî‚îÄ‚îÄ Global YouTube Statistics.csv
        ‚îú‚îÄ‚îÄ machine-learning/
        ‚îÇ   ‚îú‚îÄ‚îÄ finalized_model.pkl
        ‚îÇ   ‚îî‚îÄ‚îÄ machine-learning.ipynb
        ‚îú‚îÄ‚îÄ app.py
        ‚îú‚îÄ‚îÄ Dockerfile
        ‚îî‚îÄ‚îÄ requirements.txt
```

## Dataset utilizado: Global Youtube Statistics
O dataset pode ser encontrado em: https://www.kaggle.com/datasets/nelgiriyewithana/global-youtube-statistics-2023

## Machine Learning Algorithm: Linear Regression

A regress√£o linear √© um dos modelos de aprendizado de m√°quina mais simples e interpret√°veis. √â f√°cil de entender e implementar, o que o torna uma excelente escolha para n√≥s. (At√© porque odeio an√°lise de dados e n√£o quero ir al√©m disso... Desculpa Murilo üòÖ)

No contexto de prever visualiza√ß√µes de v√≠deos no YouTube, isso significa encontrar uma equa√ß√£o que descreve como os atributos dos v√≠deos (os dados usados para a predi√ß√£o) se relacionam com o n√∫mero de visualiza√ß√µes. √â uma t√©cnica simples e interpret√°vel que pode ajudar a entender e otimizar o desempenho dos v√≠deos.

## API: FastAPI

A API possui apenas duas rotas:
- GET ('/') -> Retorna um Hello World simples
- POST ('/predict') -> A partir dos dados passados para o modelo, retorna uma predi√ß√£o do video_views do canal em quest√£o

### Para rodar o projeto:

1. Baixe a imagem do reposit√≥rio hallzero/predict [aqui!](https://hub.docker.com/repository/docker/hallzero/prediction/general)
2. Rode o comando no terminal:
```
docker run -p 8000:8000 --name nome_exemplo hallzero/predict:0.0.1
```
3. O FastAPI gera uma documenta√ß√£o autom√°tica em ('/docs'). Na aba explicando o ('/predict'), utilize o template de input para fazer a predi√ß√£o, que ser√° devolvida como a respota √† requisi√ß√£o.

Pontos de melhoria observados:
- Preciso aprender melhor a lidar com dados categ√≥ricos
- Aprender a modularizar o processo de limpeza dos dados, a fim de n√£o depender de rodar o notebook ou colocar o mesmo c√≥digo na API

# Ponderada 4

üöß WIP üöß

# Ponderada 5 - Resenha sobre o artigo
A partir da leitura do Artigo "Machine learning for internet of things data analysis: a survey", podemos tra√ßar comparativos entre os conceitos nele apresentados, as atividades ponderadas e o projeto desenvolvido durante o m√≥dulo. Nesse contexto, podemos evidenciar t√≥picos:

## IoT, Smart Data e Dados

Segundo o artigo, o prop√≥sito da Internet of Things (IoT) √© desenvolver ambientes inteligentes e simplificar o estilo de vida ao poupar tempo, energia e dinheiro, conscintindo em dispositivos conectados uns aos outros para aprimorar suas performaces. Dessa forma, o processo de coletar dados atrav√©s de sensores, extrair informa√ß√µes a partir deles e, por fim transferir esse conhecimento para outros objetos, dispoitivos e servidores √© fundamental. Nesse contexto, um cen√°rio especificado √© a aplica√ß√£o dessas tecnologias para a redu√ß√£o de custos dentro de uma empresa, que relaciona-se diretamente com o projeto do m√≥dulo. Al√©m disso, h√° a explica√ß√£o de protocolos de comunica√ß√£o (D2D, D2S, S2S), que correspondem a uma parte do transporte dos dados, e o destaque do processamento e prepara√ß√£o dos dados (Analytics at the edge, stream analisys, IoT analysis at the database) para refor√ßar as diferentes necessidades de um projeto. No nosso caso em particular, √© importante destacar o Cloud Computing, que embora n√£o seja a maneira prim√°ria de computa√ß√£o do treinamento dos modelos, pode ser uma alternativa.

Smart Data: Por ser de extrema import√¢ncia para gerar bons insights, a qualidade dos dados deve ser garantida. Devido ao grande volume de dados brutos n√£o necessariamente √∫teis ou preparados para an√°lise, deve-se construir uma camada de abstra√ß√£o a mais (feature engeneering), bem como garantir a seguran√ßa dos dados (JWT, por exemplo) para torn√°-los mais inteligentes.

## Smart city
O artigo exemplifica diversos conceitos e vantagens do uso do IoT a partir de cidades inteligentes. Embora n√£o seja diretamente relacionado, podemos tra√ßar alguns paralelos com o projeto desenvolvido:

- Smart Energy: Reduzir o consume de energia geral atrav√©s da medi√ß√£o de sensores. (Consequ√™ncia direta)
- Smart Mobility: Efeitos diversos na forma de rodar ve√≠culos, principalmente ao monitorar sua performance. (Objetivo principal)
- Urban Planning: Ajudar em decis√µes de longo-prazo. Ao coletar dados de diferentes fontes, √© poss√≠vel fazer decis√µes para o futuro e  predi√ß√µes para problemas potenciais. (Consequ√™ncia direta)
- Smart city data characteristhics: Gera dados de maneira cont√≠nua e volumosa. Processar os dados com diferentes fontes, frequ√™ncias e intreg√°-los conscistentemente e com qualidade pode ser desafiador. (Caracter√≠stica dos dados disponibilizados)
- Quality of Information (QoI): Necessidade de extrair n√≠veis mais altos de abstra√ß√£o e prover informa√ß√µes acion√°vies para outros servi√ßos. Selecionar fontes confi√°veis e combina-los √© de suma import√¢ncia. (Processo)

## Taxonomia dos algoritmos de machine learning
Devido √† gera√ß√£o massiva de dados por diferentes fontes, √© importante garantir a manuseabilidade de suas caracter√≠sticas a fim de garantir que algoritmos de machine learning sejam aplicados no escopo de smart data em projetos IoT. Em ambos projeto e atividades ponderadas, modelos de machine learning estavam presentes e a utiliza√ß√£o pontual dependia diretamente da finalidade e caracter√≠stica dos dados. As abordagens foram majoritariamente para aprendizado supervisionado e explorou-se diversas op√ß√µes de modelos e ferramentas.

Nesse contexto, trabalhamos com abordagens de s√©ries temporais, aplicando conceitos. N√£o necessariamente todos os testes deram certo, mas constituiram experi√™ncias interessantes. A seguir, destaco alguns dos conceitos mais importantes:

- Regress√£o Linear: Utilizado na predi√ß√£o de visualiza√ß√µes de um canal nas atividades ponderadas. 
- Exponential Smoothing: M√©todo que utiliza s√©ries temporais, aplicando pesos maiores √† dados mais recentes. Ideal para forecast de valores imediatos.
- Sliding-window method: Citado no artigo na sess√£o de s√©ries temporais, √© um dos principais componentes das an√°lises do grupo. Consciste na aplica√ß√£o de uma janela de tempo para determinar o comportamento de uma falha.

- Pycaret: Ferramenta que possibilitou a aplica√ß√£o de todo o ciclo da cria√ß√£o de um modelo rapidamente.
- Prophet: Framework open-source do Facebook, √© uma das ferramentas utilizadas para de realizar previs√µes em s√©ries temporais. 

## Conclus√µes
O artigo conclui que para extrair conhecimento dos dados coletados, v√°rios algor√≠tmos podem ser aplicados. Escolher um algoritmo adequado para aplica√ß√µes IoT espec√≠ficas √© um t√≥pico importante, sendo que diferentes aplica√ß√µes possuem diferentes caracter√≠sticas, com dados com propriedades distintas a serem consideradas e a taxonomia √© outro faotr importante na aplica√ß√£o de an√°lise de dados pata smart data.

Da mesma forma, √© poss√≠vel obter essas no√ß√µes no escopo pr√°tico do projeto, uma vez que o contexto √© objetivamente parecido e os processos que levam √† constru√ß√£o da aplica√ß√£o final s√£o constitu√≠dos pela utiliza√ß√£o dos pontos evidenciados. Inclusivamente, as atividades ponderadas, embora num contexto mais simples, tamb√©m apresentam um n√≠vel de complexidade que exige os conhecimentos apresentados no artigo.
